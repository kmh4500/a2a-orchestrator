# Backend server URL
NEXT_PUBLIC_BACKEND_URL=http://localhost:3001

# LLM API URL (vLLM chat completions endpoint)
# NOTE: This is now used by the backend server, not the frontend
LLM_API_URL=http://your-llm-server:8000/v1/chat/completions

# LLM Model path
# Example: /data/models/gpt-oss-120b
LLM_MODEL=/path/to/your/model
